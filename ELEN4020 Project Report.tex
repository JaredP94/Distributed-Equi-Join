% witseiepaper-2005.tex
%
%                       Ken Nixon (12 October 2005)
%
%                       Sample Paper for ELEN417/455 2005
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[10pt,twocolumn]{witseiepaper}
%
% All KJN's macros and goodies (some shameless borrowing from SPL)
\usepackage{KJN}
\usepackage[super]{nth}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{listings}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{epstopdf}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{alltt}
%\usepackage{matlab-prettifier}
\usepackage{graphicx}
\usepackage{changes}
\usepackage{makecell}
\usepackage{verbatim}
\usepackage{balance}
\usepackage{pdfpages}
\usepackage{ragged2e}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{multirow}
\usepackage{algpseudocode}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
%\usepackage{flafter}

%\newlength\myindent
%\setlength\myindent{2em}
%\newcommand\bindent{%
%	\begingroup
%	\setlength{\itemindent}{\myindent}
%	\addtolength{\algorithmicident}{\myindent}
%}
%\newcolumntype\eindent{\endgroup}
%
% PDF Info
%
\ifpdf
\pdfinfo{
	/Title (INSTRUCTIONS AND STYLE GUIDELINES FOR THE PREPARATION OF FINAL YEAR LABORATORY PROJECT PAPERS : 2005 VERSION)
	/Author (Ken J Nixon)
	/CreationDate (D:200309251200)
	/ModDate (D:200510121530)
	/Subject (ELEN417/455 Paper Format, 2005)
	/Keywords (ELEN417, ELEN455, paper, instructions, style guidelines, laboratory project)
}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
	
	\begin{titlepage}
		
		\newcommand{\HRule}{\rule{\linewidth}{0.3mm}} % Defines a new command for the horizontal lines, change thickness here
		
		\center % Center everything on the page
		
		%----------------------------------------------------------------------------------------
		%	HEADING SECTIONS
		%----------------------------------------------------------------------------------------
		\includegraphics[width=0.3\textwidth]{EIE.png}\\[1cm] % Include a department/university logo - this will require the graphicx package
		
		%----------------------------------------------------------------------------------------
		\textsc{\LARGE University of the Witwatersrand } \\[0.1cm] % Name of your university/college
		\textsc{\LARGE School of Electrical and Information Engineering }\\[1cm] % Major heading such as course name
		\textsc{\Large ELEN4020: Data Intensive Computing}\\[1.5cm] % Minor heading such as course title
		
		%----------------------------------------------------------------------------------------
		%	TITLE SECTION
		%----------------------------------------------------------------------------------------
		
		\HRule \\[0.4cm]
		{ \huge \bfseries Project Report} \\[0.4cm] % Title of your document
		\HRule \\[1.5cm]
		
		%----------------------------------------------------------------------------------------
		%	AUTHOR SECTION
		%----------------------------------------------------------------------------------------
		\textsc{\Large 	\emph{Authors:} } \\[0.1cm]	 
		
		
		\begin{minipage}{0.4\textwidth}
			\begin{flushleft} \large
				%			\emph{Author:} \\
				Kayla-Jade Butkow \\ 714227 % Your name
			\end{flushleft}
		\end{minipage}
		~
		\begin{minipage}{0.4\textwidth}
			\begin{flushright} \large
				%	\emph{Author:}\\
				Jared Ping \\ 704447
			\end{flushright}
		\end{minipage}\\[1cm]
		
		\begin{minipage}{0.4\textwidth}
			\begin{flushleft} \large
				%		\emph{Author:}\\
				Lara Timm \\ 704157
			\end{flushleft}
		\end{minipage}
		~
		\begin{minipage}{0.4\textwidth}
			\begin{flushright} \large
				%		\emph{Author:} \\
				Matthew van Rooyen \\ 706692
			\end{flushright}
		\end{minipage}\\[1cm]
		{\large Date Handed In: \nth{14} May, 2018}\\[1cm] 
\vfill	
\justify
\textbf{Abstract: } An equi-join of two large tables using a hash join implemented in parallel using MPI and OpenMP and using MapReduce have been compared and benchmarked against one another. The benchmarks evaluated the running time and memory usage for each approach in the two different algorithms. These algorithms were: . Comparison between results of both algorithms. Note the strengths and weaknesses for each approach.
		
\textbf{Key words: }
		
	\end{titlepage}


\pagestyle{plain}
\setcounter{page}{1}
\twocolumn
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Introduction}

This report describes two different algorithms for performing a Equi-Join on two large tables with comparative data. Each algorithm will be described in terms of its design, implementation, strengths and weaknesses. The performance benchmarks for each of the algorithms will be discussed along with the results if of each benchmark. These results will be comparatively analyzed with future recommendations given.

\section{Project Background}

\subsection{Parallel Join Algorithms}

The task of a join algorithm is to find, for each distinct value of a predefined join attribute, the set of tuples in each relational database which have that value. Equi Join Queries contain join predicates in a form of standard comparison using a relational operator (i.e. the = operator). The operands of these queries are collection attribute types.

Because the cost of evaluating these relational joins can be very high for large databases, it is natural to improve performance by spreading the load across multiple cooperating processors and disks of a parallel computer. In order to perform a join between two large relational data sets, a parallel algorithm must then be implemented in order to handle the workload each join operation is performing. By making these parallel, distributed join algorithms reduce processing time making the concept much more efficient on a massive scale. These algorithms can be implemented in a number of ways.

\subsubsection{Sort-Merge Join}\label{sortmerge}

The sort-merge join algorithm is based on sorting both input relations. This algorithm can be divided into two main steps. The first is the data- partitioning step which produces disjoint partitions. In this step, the sorting phase occurs by making use of each of the allocated threads to partition the input data into ranges of the same size. These partitions are known as input relations. We use range-partitioning to ensure that matching elements in both relations will be assigned to the same machine for processing. 

In the partitioning step, the object instance is partitioned based on their first elements in each list or array, or their minimum value elements associated with each collection attribute. Each partition is run individually with each run involving a sort of the data within the range which is transmitted asynchronously to the target node. The performance of the algorithm is therefore limited by the rate at which each run can be sorted and the network bandwidth available to each process at the given node.

After a process has sorted its input data, it waits until it has received all the sorted runs of its range from the other nodes. Once all the data has been received, the algorithm starts merging the sorted runs combining multiple input runs into one sorted output. The merging in class level involves finding two object instance of class A and B that has the same first element of its collection attribute. On the other hand, the collection level merge involves merging that two matched first element object instances start from the second element of their collection attribute values. Several iterations over the data might be required until both relations are fully sorted.

To compute the join result, each process merges the sorted partition of the inner relation with the corresponding partition of the outer relation.

The order of the tuples in the output is also sorted. The costs associated with materializing the output of the sort-
merge join depends on the selectivity of the input and the payload that needs to be accessed over the network.

The time required to range-partition the data depends on the size of the input relations, the number of processes p, and the partitioning rate Ppart.

\begin{comment}
	, and the second step is joining.  In the joining step, the collection elements for all object instance of class A and B need to be sorted in ascend- ing order (for sets/bags only). These two classes are then sorted based on the first element of the collection type attribute. Subsequently, these two classes are merged in class and collection level. 
\end{comment}


\subsubsection{Hash Join}

Hash join is used in relational database management of a join algorithm. Similar to that of a Sort-Merge join mentioned in \ref{sortmerge}, Hash joins require an equijoin predicate comparing values from one table with values from the other table using the equals operand.

The algorithm has a build phase and a probe phase. At the start of the build phase, all the threads allocate memory locally. The union of these memory fragments constitutes a single hash table that is shared by all the threads. The build phase reads in the smaller joining relation, R, from the disk once only in order to construct a hash table in memory  by performing a predefined hash function on the join key. The build phase is completed when all the R tuples have been stored in the hash table. The second relation is then read in afterwhich each tuple probes the hash table in order to search for matching tuples between the two relations.

The algorithm makes use of whatever memory is available to it and writes the rest to the disk.

\begin{comment}
	Thread i then reads a tuple r ∈ R and hashes on the join key of r us-
	ing a pre-defined hash function h(·). It then acquires a latch on bucket h(r), copies r in this bucket, and releases
	the latch. The memory writes required for this operation may either target local or remote NUMA memory. 
	
	Hybrid and Grace. Existing Solutions.
	
	In this algorithm, the sorting step is not necessary. The only item that needs to be sorted is the collection attribute of type set or bag. A single chained hash table is used to store the object instances. Initially, the object is placed into the hash table by hashing the first elements of collection attributes. By doing so, all the object instances with the same first element value will go to the same bucket. These object instances are chained together using a list data structure. To perform the collection equi-join, each object instances of class B is hashed based on the first element of its collection attribute. This will directly find the object of class A that has the same first element of collection attribute. The object instances of class B are then compared to all chained object of class A by using the comparison algorithm in Figure 3
	
	Hash join is similar to nested loop join but faster than nested loop join and hash join is used for equi-join.
\end{comment}

\subsection{OpenMP}

The OpenMP library was developed to provide an API which could run the same code base, equally well,
across a range of operating systems. The OpenMP library takes the form of a set of compiler directives (pragmas) which are operating system-specific. Through the sensible use of OpenMP pragmas, a single threaded program can be parallelised while maintaining its serial structure.

3.1. OpenMP. OpenMP is a shared-memory multiprocessing
application program inference (API) for easy development
of shared memory parallel programs [9]. It provides a set of

compiler directives to create threads, synchronize the opera-
tions, and manage the shared memory on top of pthreads.The

programs using OpenMP are compiled into multithreaded
programs, in which threads share the same memory address
space and hence the communications between threads can be
very efficient.

\subsection{MPI}

Message passing is a form of communication between two separate processes in parallel or object-orientated programming. By using this model, objects can send and receive a number of resources between each other. The passing of the messages or resources can be synchronous or asynchronous. Synchronous systems incur a waiting period while the sender and receiver wait for the message to be transferred where as asynchronous can carry on with other computations while the message is passed.  

The Message-Passing Interface (MPI) is a widely used interface in high-performance computing systems. In the following section, we provide an introduction to MPI, and a detailed description of the one-sided MPI operations, used in our join implementations. MPI is used mainly for parallel computers, clusters or a heterogenous network which is a connection of different computers or devices with a variety of operating systems and protocols.

MPI can be used for a variety of parallel computing models. These models can either perform the parallelization of data where the same instructions are carried out simultaneously on multiple data items (SIMD) or task parallelization where different instructions are performed on separate sections of data (MIMD). Message Passing is used to for MIMD, also known as SPMD (Single Program, Multiple Data), in order to perform parallelism. MPI provides a powerful and efficient means of expressing parallel programs in a portable manner.

\subsection{MapReduce}

MapReduce is a functional language-inspired parallel programing model for large-scale machines. Its simplicity, coupled with its applicability to practical problems, has led to adoption on a range of computing platforms. 

While cluster-based MapReduce performance is limited primarily by disk and network I/O, shared-memory Map-Reduce performance, without these bottlenecks, is sensitive to a wide range of workload-influenced details such as intermediate key-value data layout, memory allocation pressure,and framework overhead.

The Phoenix project [9, 12], in particular, demonstrated that the MapReduce model could be used on shared-memory machines, with scalability comparable, in some cases, to hand-coded PThreads solutions.

\subsection{Existing Solutions}

\section{System Design and Implementation}
The two implemented solutions are a hybrid equi-join using MPI and OpenMP, and an equi-join implemented using MapReduce. The hybrid solution makes use of the framework set out by the serial solution, but extends it using MPI and OpenMP.

\subsection{Serial Equi-Join}
An object-oriented solution was implemented for the serial equi-join. Within this solution, three classes were created, namely, \texttt{hashFunction}, \texttt{joinManager} and \texttt{fileManager}. The \texttt{fileManager} class is responsible for any functionality relating to the management of files. Within the \texttt{fileManager} class, the input text files are read in and split by delimiter and by end of line character. The data is returned in the form of a vector which contains a key in every even index and the original line from the text file in every odd index.

Once the two input files have been read in and mapped to two vectors, an instance of the the \texttt{hashFunction} class is used to created a hash table. Since a simple hash-join algorithm was implemented, a hash table was only created for one of the input text files \cite{evaluating4JoinAlgorithms}. In creating the table, each key was hashed using \ref{eqn:hash}. By creating a hash of the key, a corresponding (index,(key, value)) pair is created, where the index refers to the location of the value in the hash table. In order to avoid the need for contiguous memory to store the hash table, the table was created as a series of pointers which each point to the next value in the table. If multiple keys are hashed to produce the same index, buckets are created which hold all of the (key,value) pairs with the same hash. The implication of using a hash table is that when searching for a key, the entire table does not need to be searched. Rather, the the key of interest is hashed, and then only the corresponding index in the table is searched for the required key.

\begin{equation}
 \\
\label{eqn:hash}
\end{equation}

Once the first file has been hashed, the hash table must be probed by the tuples in the second file. To do this, the key is hashed to find its corresponding index in the hash table. Thereafter, each key in the hash table is checked for equality with the probing key. If they are found to be equal (thus satisfying the conditions of an equi-join), the (key,value) pair in the hash table is added to a vector of results. Once the whole bucket has been probed, the vector contains all of the (key, value) pairs that must be joined to the probing key, and it is returned.

Finally, the \texttt{joinManager} class handles the joining of the two tables. In the \texttt{joinManager} class, the value from each resulting (key, value) is appended onto the probing (key, value) pair in order to join the tables. To reduce repetition of the key in the joined table, the key is extracted from the resulting value prior to appending the strings. The joined strings are then appended to a vector. This process occurs for each (key,value) pair in the second file. Finally, the vector containing the joined table is returned and written to an output text file.

\subsection{Hybrid Equi-Join}

\subsection{MapReduce Equi-Join}


%\subsection{File System Design}
%
%\subsection{Code Framework}
%
%The algorithm was constructed using C++ and Message Passing Interface library (MPI). MPI libraries consist of message-passing functionality which was used for distributed and parallel algorithms. Message passing function is simply a func- tion that explicitly transmits data from one process to another. By using MPI library each process that is running on an individual workstation is assigned a unique number called process rank. The root process will coordinate most of the operation for the parallel data joining implementation. The equi-join employed the data parallelism paradigm. Data is partitioned to different process for local processing. The main MPI library functions used in our implementation are Send, Receive, Broadcast, Gather, and All-to-All communication
%
%\subsection{Join Algorithm}
%
%Parallel collection equi-join can be divided into two main phases. The first phase is data partitioning based on disjoint partition, and the second phase is per- forming the join algorithm(i.e. sort-merge or hash join). The hash join algorithm was chosen for this.
%
%\subsection{Multi-threading Environment}
%
%OpenMP. Each node has 4 cores, 8 threads. 
%
%
%Compared to using pthreads and working with mutex and
%condition variables, OpenMP is much easier to use because
%the compiler takes care of transforming the sequential code
%into parallel code according to the directives [12]. Hence
%the programmers can write multithreaded programs without
%serious understanding of multithreading mechanism. Its
%runtime maintains the thread pool and provides a set of
%libraries [7].
%It uses a block-structured approach to switch between
%sequential and parallel sections, which follows the fork/join
%model. At the entry of a parallel block, a single thread of
%control is split into some number of threads, and a new
%sequential thread is started when all the split threads have
%finished. Its directives allow the fine-grained control over
%the threads. It is supported on various platforms like UNIX,
%LINUX, and Windows and various languages like C, C++,
%and Fortran [12].
%
%
%In OODB, collection equi-join is based on ’total’ equality. That is, for list/array each collection type element (OID) must be equal in the same order. Whereas for set/bag two objects are equal if all collection type element object of class A exist in object of class B in any order. Before the joining can take place, the local objects for class A and B needs to be sorted. We used quick sort with algorithm in Figure 3 as the comparison function. The algorithm performs element-by-element comparison between two collec- tion attributes until one of the OIDs is not equal or it reaches the end of one of the collection attributes. For this comparison to perform correctly, collection attributes of type set or bag must be pre-sorted

\section{Results}

Comparison between MapReduce and given algorithm.

\section{Critical Analysis}
A strength of the designed solutions is that both solutions are able to perform equi-join operations on an column of a table. Furthermore, the hybrid solution is able to handle any type of delimiter within a file.

\subsection{Limitations}

\subsection{Tradeoffs}

\section{Future Recommendations}
For future recommendations, a hybrid hash-join algorithm should be implemented rather than a simple hash-join. This would improve performance at all levels of memory availability \cite{evaluating4JoinAlgorithms}.

\section{Conclusion}

\bibliographystyle{witseie}
\bibliography{bigData}
\end{document}